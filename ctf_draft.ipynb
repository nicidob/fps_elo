{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import pickle\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_table= pd.read_csv('ctf_draft - players.csv')\n",
    "in_table.name = [_.strip().rstrip() for _ in in_table.name]\n",
    "max_id = 9223372036854775808\n",
    "id_lookup = {}\n",
    "pick_lookup = {}\n",
    "out_table = in_table.set_index('name')\n",
    "for row in out_table.itertuples():\n",
    "    if np.isnan(row[1]): continue\n",
    "    id_lookup[int(row[1])] = row[0]\n",
    "    pick_lookup[row[0]] = row[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_lookup = {row[1]:row[2] for row in pd.read_csv('ctf_draft - ratings.csv').itertuples()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array(list(id_lookup.keys())).astype(np.uint64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weapon_url = 'https://qlstats.net/player/{:d}/weaponstats.json?limit=100&game_type=ctf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weapon_stats = {}\n",
    "with open('ctf_stats.pkl','rb') as fp:\n",
    "    weapon_stats = pickle.load(fp)\n",
    "    \n",
    "for qlid in ids:\n",
    "    if qlid == max_id:\n",
    "        continue\n",
    "    if qlid in weapon_stats:\n",
    "        continue\n",
    "    req = requests.get(weapon_url.format(qlid))\n",
    "    weap = req.json()\n",
    "    weapon_stats[qlid] = weap\n",
    "    time.sleep(1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weapon_stats.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in weapon_stats.items():\n",
    "    if len(v['averages']) == 0:\n",
    "        print(k)\n",
    "weapon_stats2 = {k:v for k,v in weapon_stats.items() if len(v['averages'])!=0}\n",
    "weapon_stats = weapon_stats2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ctf_stats.pkl','wb') as fp:\n",
    "    pickle.dump(weapon_stats,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weapon_table = []\n",
    "for pid, weap_stats in weapon_stats.items():\n",
    "    w_s = defaultdict(int)\n",
    "    gs = []\n",
    "    for ws in weap_stats['weapon_stats']:\n",
    "        gs.append(ws['game_id'])\n",
    "        w = ws['weapon_cd']\n",
    "        w_s[w + '_shots'] += ws['fired']\n",
    "        w_s[w + '_hits'] += ws['hit']\n",
    "        w_s[w + '_frags'] += ws['frags']\n",
    "    gs = len(set(gs))\n",
    "    w_s = {k:v/gs for k,v in w_s.items()}\n",
    "    for w in set([_.split('_')[0] for _ in w_s.keys()]):\n",
    "        w_s[w+'_acc'] = w_s[w+'_hits']/(w_s[w+'_shots']+1e-3)\n",
    "    w_s['pid'] = pid\n",
    "    w_s['games'] = gs\n",
    "    weapon_table.append(w_s)\n",
    "weapon_table = pd.DataFrame(weapon_table).set_index('pid').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED = (( weapon_table['lg_frags'] / 26.74 ) + ( weapon_table['rl_frags'] / 24.21 ) + ( weapon_table['rg_frags'] / 43.04 ) + ( weapon_table['pg_acc'] * 2.81 ) + ( weapon_table['sg_acc'] * 1.85 ) + ( weapon_table['rg_hits'] / 151.91 ) + ( weapon_table['rl_hits'] / 162.64 ) + ( weapon_table['rg_shots'] / 291.07 ) + ( weapon_table['lg_shots'] / 3466.37 ) + ( weapon_table['sg_frags'] / 40.76 ) + ( weapon_table['rg_acc'] / 1.39 ) + ( weapon_table['rl_acc'] * 1.17 ) + ( weapon_table['gl_shots'] / 291.65 ) + ( weapon_table['lg_hits'] / 2306.52 ) + ( weapon_table['rl_shots'] / 933.4 ) + ( weapon_table['sg_hits'] / 2111.11 ) + ( weapon_table['gt_frags'] / 6.6 ) + ( weapon_table['pg_hits'] / 431.71 ) + ( weapon_table['pg_frags'] / 45.56 ) + ( weapon_table['lg_acc'] / 4.89 ) + ( weapon_table['pg_shots'] / 5830.2 ))\n",
    "PRED = (PRED-PRED.mean())/PRED.std()\n",
    "PRED2 = (( weapon_table['lg_hits'] / 8.25 ) + ( weapon_table['lg_shots'] / -26.05 ) + ( weapon_table['sg_shots'] / -26.32 ) + ( weapon_table['rg_hits'] / 1.09 ) + ( weapon_table['sg_hits'] / 8.53 ) + ( weapon_table['lg_frags'] * 1.49 ) + ( weapon_table['sg_frags'] * 1.5 ) + ( weapon_table['rl_hits'] / 2.55 ) + ( weapon_table['rg_shots'] / -5.5 ) + ( weapon_table['mg_shots'] / -32.42 ) + ( weapon_table['rg_frags'] / 1.75 ) + ( weapon_table['pg_hits'] / 3.76 ) + ( weapon_table['mg_acc'] * 74.12 ) + ( weapon_table['mg_hits'] / 15.33 ) + ( weapon_table['gl_hits'] / -0.8 ) + ( weapon_table['gl_shots'] / 10.01 ) + ( weapon_table['rl_frags'] / 2.02 ) + ( weapon_table['pg_shots'] / -53.23 ) + ( weapon_table['pg_acc'] * 26.81 ) + ( weapon_table['rl_shots'] / -40.33 ) + ( weapon_table['sg_acc'] * 13.31 ) + ( weapon_table['gt_frags'] * 2.08 ) + ( weapon_table['mg_frags'] / 2.4 ) + ( weapon_table['rg_acc'] * 6.47 ) + ( weapon_table['pg_frags'] / 2.48 ) + ( weapon_table['lg_acc'] / -0.18 ) + ( weapon_table['rl_acc'] * 5.36 ))\n",
    "PRED2 = (PRED2-PRED2.mean())/PRED2.std()\n",
    "\n",
    "\n",
    "PRED_F = 50 + 8*(PRED+PRED2)\n",
    "weapon_table['PRED_1'] = 50 + 16*(PRED)\n",
    "weapon_table['PRED_2'] = 50 + 16*(PRED2)\n",
    "\n",
    "weapon_table['PRED_Total'] = PRED_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weapon_table.sort_values('PRED_Total',0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weapon_table.index = [id_lookup.get(_,str(np.random.randint(3200))) for _ in weapon_table.index ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_t2 = pd.concat([out_table,weapon_table],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_t2['pick'] = np.array(out_t2.index.map(lambda x: pick_lookup.get(x,'')))\n",
    "out_t2.sort_values('PRED_Total',0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_t2.sort_values('PRED_Total',0,False)[['pick','games','PRED_1','PRED_2','PRED_Total']].to_csv('out_ctf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_t2.sort_values('PRED_Total',0,False)[['pick','games','PRED_Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = out_t2.copy()\n",
    "true_order = []\n",
    "for row in dft[['pick']].itertuples():\n",
    "    if 'c' in row[1]:\n",
    "        to = -int(row[1][1:])\n",
    "    elif 'X' in row[1] or '' == row[1]:\n",
    "        to = 0\n",
    "        pass\n",
    "    else:\n",
    "        to = row[1]\n",
    "    true_order.append(int(to))\n",
    "dft['true_o'] = true_order\n",
    "dft = dft.sort_values('true_o')\n",
    "dft = dft[dft.true_o!=0]\n",
    "teamc = list(dft.index[:(dft.true_o < 0).sum()])\n",
    "teamc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_teams = len(teamc)\n",
    "ti = 0\n",
    "counter = 1\n",
    "teams = []\n",
    "for idx,row in enumerate(dft.itertuples()):\n",
    "    teams.append(ti)\n",
    "    print(ti,idx,row[-1],row[0])\n",
    "    ti+=counter\n",
    "    \n",
    "    if ti == total_teams:\n",
    "        ti = total_teams-1\n",
    "        counter = -1\n",
    "    if ti == -1:\n",
    "        ti = 0\n",
    "        counter = 1\n",
    "dft['team'] = teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(dpi=120)\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.style.use('seaborn-white')\n",
    "dft_f = dft[~ np.isnan(dft.PRED_Total)]\n",
    "dft_f = dft_f[dft.true_o > 0]\n",
    "\n",
    "pick_names = list(dft_f.sort_values('PRED_Total',0,False).index)\n",
    "exp_pick = [pick_names.index(_) for _ in dft_f.index]\n",
    "actual_pick = np.arange(len(exp_pick))\n",
    "plt.scatter(actual_pick,exp_pick,s=10,alpha=0.5)\n",
    "plt.grid(True)\n",
    "plt.xlabel('True pick')\n",
    "plt.ylabel('Est pick')\n",
    "plt.title('R = {:.2f}'.format(-dft_f[['PRED_Total','true_o']].corr().iloc[1,0]))\n",
    "\n",
    "n_d = len(exp_pick)\n",
    "for i in range(n_d):\n",
    "    y = int(exp_pick[i])\n",
    "    plt.text(i,y,dft_f.index[i],size=8,va='center',ha='center')\n",
    "plt.plot([0,n_d],[0,n_d],c='k',ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as linear\n",
    "clf = linear.LinearRegression()\n",
    "dft_f2 = dft.dropna(subset=['PRED_Total'])\n",
    "clf.fit(np.array(dft_f2.true_o[total_teams:])[:,None],dft_f2.PRED_Total[total_teams:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rating = clf.coef_[0] * dft.true_o + clf.intercept_\n",
    "dft['PRED_S'] = np.where(np.isnan(dft.PRED_Total),pred_rating,dft.PRED_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_res = dft[['team','true_o','PRED_S']].sort_values('PRED_S',0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_avgs = defaultdict(list)\n",
    "team_names = defaultdict(list)\n",
    "team_cap = dict()\n",
    "for row in draft_res.iterrows():\n",
    "    team_avgs[row[1].team].append(row[1].PRED_S)\n",
    "    team_names[row[1].team].append(row[0])\n",
    "    if(row[1].true_o < 0):\n",
    "        team_cap[row[1].team] = row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_ratings = {}\n",
    "for i in np.arange(total_teams):\n",
    "    \n",
    "    vals = sorted([_ for _ in team_avgs[i] if not np.isnan(_)])[::-1]\n",
    "    wN = len(vals)\n",
    "    v = np.arange(wN)+1\n",
    "    wT = [1 if idx < 4 else 0.4-idx*0.05 for idx in range(wN)]#0.7+0.3*np.tanh(-1*(v-5))\n",
    "    V = sum([w*v for w,v in zip(wT,vals)])\n",
    "\n",
    "    \n",
    "    team_c = sorted([(0 if np.isnan(v) else v,k) for k,v in zip (team_names[i], team_avgs[i])])[::-1]\n",
    "    team_c = ', '.join(['{} ({:.1f})'.format(v,k) for k,v in team_c])\n",
    "    \n",
    "    cap = team_cap[i] + '\\n' + team_c\n",
    "    team_ratings[cap] = V/sum(wT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(wT,vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,p in enumerate(sorted([(round(v,1),k) for k,v in team_ratings.items()])[::-1]):\n",
    "    print('TEAM {}'.format(i+1),p[0],p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(team_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(team_avgs),len(team_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_names[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_cap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
